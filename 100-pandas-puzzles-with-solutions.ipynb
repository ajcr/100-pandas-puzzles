{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 pandas puzzles\n",
    "\n",
    "Inspired by [100 Numpy exerises](https://github.com/rougier/numpy-100), here are 100* short puzzles for testing your knowledge of [pandas'](http://pandas.pydata.org/) power.\n",
    "\n",
    "Since pandas is a large library with many different specialist features and functions, these excercises focus mainly on the fundamentals of manipulating data (indexing, grouping, aggregating, cleaning), making use of the core DataFrame and Series objects. \n",
    "\n",
    "Many of the excerises here are stright-forward in that the solutions require no more than a few lines of code (in pandas or NumPy... don't go using pure Python or Cython!). Choosing the right methods and following best practices is the underlying goal.\n",
    "\n",
    "The exercises are loosely divided in sections. Each section has a difficulty rating; these ratings are subjective, of course, but should be a seen as a rough guide as to how inventive the required solution is.\n",
    "\n",
    "If you're just starting out with pandas and you are looking for some other resources, the official documentation  is very extensive. In particular, some good places get a broader overview of pandas are...\n",
    "\n",
    "- [10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "- [pandas basics](http://pandas.pydata.org/pandas-docs/stable/basics.html)\n",
    "- [tutorials](http://pandas.pydata.org/pandas-docs/stable/tutorials.html)\n",
    "- [cookbook and idioms](http://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook)\n",
    "\n",
    "Enjoy the puzzles!\n",
    "\n",
    "\\* *the list of exercises is not yet complete! Pull requests or suggestions for additional exercises, corrections and improvements are welcomed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pandas\n",
    "\n",
    "### Getting started and checking your pandas setup\n",
    "\n",
    "Difficulty: *easy* \n",
    "\n",
    "**1.** Import pandas under the name `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Print the version of pandas that has been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Print out all the version information of the libraries that are required by the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame basics\n",
    "\n",
    "### A few of the fundamental routines for selecting, sorting, adding and aggregating data in DataFrames\n",
    "\n",
    "Difficulty: *easy*\n",
    "\n",
    "Note: remember to import numpy using:\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "Consider the following Python dictionary `data` and Python list `labels`:\n",
    "\n",
    "``` python\n",
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "```\n",
    "(This is just some meaningless data I made up with the theme of animals and trips to a vet.)\n",
    "\n",
    "**4.** Create a DataFrame `df` from this dictionary `data` which has the index `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Display a summary of the basic information about this DataFrame and its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "# ...or...\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Return the first 3 rows of the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:3]\n",
    "\n",
    "# or equivalently\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Select just the 'animal' and 'age' columns from the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['animal', 'age']]\n",
    "\n",
    "# or\n",
    "\n",
    "df[['animal', 'age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Select the data in rows `[3, 4, 8]` *and* in columns `['animal', 'age']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.ix[[3, 4, 8], ['animal', 'age']]",
    "\n",
    "#-- OR -- (non-ix solution, since ix is being deprecated)",
    "\n",
    "df.iloc[[3,4,8]][['animal', 'age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Select only the rows where the number of visits is greater than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['visits'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** Select the rows where the age is missing, i.e. is `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** Select the rows where the animal is a cat *and* the age is less than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[(df['animal'] == 'cat') & (df['age'] < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.** Select the rows the age is between 2 and 4 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['age'].between(2, 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** Change the age in row 'f' to 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc['f', 'age'] = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** Calculate the sum of all visits (the total number of visits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['visits'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** Calculate the mean age for each different animal in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('animal')['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16.** Append a new row 'k' to `df` with your choice of values for each column. Then delete that row to return the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc['k'] = [5.5, 'dog', 'no', 2]\n",
    "\n",
    "# and then deleting the new row...\n",
    "\n",
    "df = df.drop('k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17.** Count the number of each type of animal in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['animal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18.** Sort `df` first by the values in the 'age' in *decending* order, then by the value in the 'visit' column in *ascending* order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['age', 'visits'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19.** The 'priority' column contains the values 'yes' and 'no'. Replace this column with a column of boolean values: 'yes' should be `True` and 'no' should be `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['priority'] = df['priority'].map({'yes': True, 'no': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** In the 'animal' column, change the 'snake' entries to 'python'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['animal'] = df['animal'].replace('snake', 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21.** For each animal type and each number of visits, find the mean age. In other words, each row is an animal, each column is a number of visits and the values are the mean ages (hint: use a pivot table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index='animal', columns='visits', values='age', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames: beyond the basics\n",
    "\n",
    "### Slightly trickier: you may need to combine two or more methods to get the right answer\n",
    "\n",
    "Difficulty: *medium*\n",
    "\n",
    "The previous section was tour through some basic but essential DataFrame operations. Below are some ways that you might need to cut your data, but for which there is no single \"out of the box\" method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22.** You have a DataFrame `df` with a column 'A' of integers. For example:\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n",
    "```\n",
    "\n",
    "How do you filter out rows which contain the same integer as the row immediately above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['A'].shift() != df['A']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23.** Given a DataFrame of numeric values, say\n",
    "```python\n",
    "df = pd.DataFrame(np.random.random(size=(5, 3))) # a 5x3 frame of float values\n",
    "```\n",
    "\n",
    "how do you subtract the row mean from each element in the row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sub(df.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** Suppose you have DataFrame with 10 columns of real numbers, for example:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
    "```\n",
    "Which column of numbers has the smallest sum? (Find that column's label.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sum().idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.** How do you count how many unique rows a DataFrame has (i.e. ignore all rows that are duplicates)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df) - df.duplicated(keep=False).sum()\n",
    "\n",
    "# or perhaps more simply...\n",
    "\n",
    "len(df.drop_duplicates(keep=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three puzzles are slightly harder...\n",
    "\n",
    "**26.** You have a DataFrame that consists of 10 columns of floating--point numbers. Suppose that exactly 5 entries in each row are NaN values. For each row of the DataFrame, find the *column* which contains the *third* NaN value.\n",
    "\n",
    "(You should return a Series of column labels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df.isnull().cumsum(axis=1) == 3).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**27.** A DataFrame has a column of groups 'grps' and and column of numbers 'vals'. For example: \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), \n",
    "                   'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "```\n",
    "For each *group*, find the sum of the three greatest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('grp')['vals'].nlargest(3).sum(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**28.** A DataFrame has two integer columns 'A' and 'B'. The values in 'A' are between 1 and 100 (inclusive). For each group of 10 consecutive integers in 'A' (i.e. `(0, 10]`, `(10, 20]`, ...), calculate the sum of the corresponding values in column 'B'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(pd.cut(df['A'], np.arange(0, 101, 10)))['B'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames: harder problems \n",
    "\n",
    "### These might require a bit of thinking outside the box...\n",
    "\n",
    "...but all are solvable using just the usual pandas/NumPy methods (and so avoid using explicit `for` loops).\n",
    "\n",
    "Difficulty: *hard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**29.** Consider a DataFrame `df` where there is an integer column 'X':\n",
    "```python\n",
    "df = pd.DataFrame({'X': [7, 2, 0, 3, 4, 2, 5, 0, 3, 4]})\n",
    "```\n",
    "For each value, count the difference back to the previous zero (or the start of the Series, whichever is closer). These values should therefore be `[1, 2, 0, 1, 2, 3, 4, 0, 1, 2]`. Make this a new column 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "izero = np.r_[-1, (df['X'] == 0).nonzero()[0]] # indices of zeros\n",
    "idx = np.arange(len(df))\n",
    "df['Y'] = idx - izero[np.searchsorted(izero - 1, idx) - 1]\n",
    "\n",
    "# http://stackoverflow.com/questions/30730981/how-to-count-distance-to-the-previous-zero-in-pandas-series/\n",
    "# credit: Behzad Nouri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an alternative approach based on a [cookbook recipe](http://pandas.pydata.org/pandas-docs/stable/cookbook.html#grouping):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = (df['X'] != 0).cumsum()\n",
    "y = x != x.shift()\n",
    "df['Y'] = y.groupby((y != y.shift()).cumsum()).cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**30.** Consider a DataFrame containing rows and columns of purely numerical data. Create a list of the row-column index locations of the 3 largest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.unstack().sort_values()[-3:].index.tolist()\n",
    "\n",
    "# http://stackoverflow.com/questions/14941261/index-and-column-for-the-max-value-in-pandas-dataframe/\n",
    "# credit: DSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**31.** Given a DataFrame with a column of group IDs, 'grps', and a column of corresponding integer values, 'vals', replace any negative values in 'vals' with the group mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace(group):\n",
    "    mask = group<0\n",
    "    group[mask] = group[~mask].mean()\n",
    "    return group\n",
    "\n",
    "df.groupby(['grps'])['vals'].transform(replace)\n",
    "\n",
    "# http://stackoverflow.com/questions/14760757/replacing-values-with-groupby-means/\n",
    "# credit: unutbu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**32.** Implement a rolling mean over groups with window size 3, which ignores NaN value. For example consider the following DataFrame:\n",
    "\n",
    "```python\n",
    ">>> df = pd.DataFrame({'group': list('aabbabbbabab'),\n",
    "                       'value': [1, 2, 3, np.nan, 2, 3, \n",
    "                                 np.nan, 1, 7, 3, np.nan, 8]})\n",
    ">>> df\n",
    "   group  value\n",
    "0      a    1.0\n",
    "1      a    2.0\n",
    "2      b    3.0\n",
    "3      b    NaN\n",
    "4      a    2.0\n",
    "5      b    3.0\n",
    "6      b    NaN\n",
    "7      b    1.0\n",
    "8      a    7.0\n",
    "9      b    3.0\n",
    "10     a    NaN\n",
    "11     b    8.0\n",
    "```\n",
    "The goal is to compute the Series:\n",
    "\n",
    "```\n",
    "0     1.000000\n",
    "1     1.500000\n",
    "2     3.000000\n",
    "3     3.000000\n",
    "4     1.666667\n",
    "5     3.000000\n",
    "6     3.000000\n",
    "7     2.000000\n",
    "8     3.666667\n",
    "9     2.000000\n",
    "10    4.500000\n",
    "11    4.000000\n",
    "```\n",
    "E.g. the first window of size three for group 'b' has values 3.0, NaN and 3.0 and occurs at row index 5. Instead of being NaN the value in the new column at this row index should be 3.0 (just the two non-NaN values are used to compute the mean (3+3)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = df.groupby(['group'])['value']              # group values  \n",
    "g2 = df.fillna(0).groupby(['group'])['value']    # fillna, then group values\n",
    "\n",
    "s = g2.rolling(3, min_periods=1).sum() / g1.rolling(3, min_periods=1).count() # compute means\n",
    "\n",
    "s.reset_index(level=0, drop=True).sort_index()  # drop/sort index\n",
    "\n",
    "# http://stackoverflow.com/questions/36988123/pandas-groupby-and-rolling-apply-ignoring-nans/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series and DatetimeIndex\n",
    "\n",
    "### Exercises for creating and manipulating Series with datetime data\n",
    "\n",
    "Difficulty: *easy/medium*\n",
    "\n",
    "pandas is fantastic for working with dates and times. These puzzles explore some of this functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**33.** Create a DatetimeIndex that contains each business day of 2015 and use it to index a Series of random numbers. Let's call this Series `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dti = pd.date_range(start='2015-01-01', end='2015-12-31', freq='B') \n",
    "s = pd.Series(np.random.rand(len(dti)), index=dti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**34.** Find the sum of the values in `s` for every Wednesday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s[s.index.weekday == 2].sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**35.** For each calendar month in `s`, find the mean of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**36.** For each group of four consecutive calendar months in `s`, find the date on which the highest value occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.groupby(pd.TimeGrouper('4M')).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**37.** Create a DateTimeIndex consisting of the third Thursday in each month for the years 2015 and 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.date_range('2015-01-01', '2016-12-31', freq='WOM-3THU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "### Making a DataFrame easier to work with\n",
    "\n",
    "Difficulty: *easy/medium*\n",
    "\n",
    "It happens all the time: someone gives you data containing malformed strings, Python, lists and missing data. How do you tidy it up so you can get on with the analysis?\n",
    "\n",
    "Take this monstrosity as the DataFrame to use in the following puzzles:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', \n",
    "                               'Budapest_PaRis', 'Brussels_londOn'],\n",
    "              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', \n",
    "                               '12. Air France', '\"Swiss Air\"']})\n",
    "```\n",
    "(It's some flight data I made up; it's not meant to be accurate in any way.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**38.** Some values in the the FlightNumber column are missing. These numbers are meant to increase by 10 with each row so 10055 and 10075 need to be put in place. Fill in these missing numbers and make the column an integer column (instead of a float column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['FlightNumber'] = df['FlightNumber'].interpolate().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**39.** The From\\_To column would be better as two separate columns! Split each string on the underscore delimiter `_` to give a new temporary DataFrame with the correct values. Assign the correct column names to this temporary DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = df.From_To.str.split('_', expand=True)\n",
    "temp.columns = ['From', 'To']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**40.** Notice how the capitalisation of the city names is all mixed up in this temporary DataFrame. Standardise the strings so that only the first letter is uppercase (e.g. \"londON\" should become \"London\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp['From'] = temp['From'].str.capitalize()\n",
    "temp['To'] = temp['To'].str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**41.** Delete the From_To column from `df` and attach the temporary DataFrame from the previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('From_To', axis=1)\n",
    "df = df.join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**42**. In the Airline column, you can see some extra puctuation and symbols have appeared around the airline names. Pull out just the airline name. E.g. `'(British Airways. )'` should become `'British Airways'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Airline'] = df['Airline'].str.extract('([a-zA-Z\\s]+)', expand=False).str.strip()\n",
    "# note: using .strip() gets rid of any leading/trailing spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**43**. In the RecentDelays column, the values have been entered into the DataFrame as a list. We would like each first value in its own column, each second value in its own column, and so on. If there isn't an Nth value, the value should be NaN.\n",
    "\n",
    "Expand the Series of lists into a DataFrame named `delays`, rename the columns `delay_1`, `delay_2`, etc. and replace the unwanted RecentDelays column in `df` with `delays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# there are several ways to do this, but the following approach is possibly the simplest\n",
    "\n",
    "delays = df['RecentDelays'].apply(pd.Series)\n",
    "\n",
    "delays.columns = ['delay_{}'.format(n) for n in range(1, len(delays.columns)+1)]\n",
    "\n",
    "df = df.drop('RecentDelays', axis=1).join(delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame should look much better now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using MultiIndexes\n",
    "\n",
    "### Go beyond flat DataFrames with additional index levels\n",
    "\n",
    "Difficulty: *medium*\n",
    "\n",
    "Previous exercises have seen us analysing data from DataFrames equipped with a single index level. However, pandas also gives you the possibilty of indexing your data using *multiple* levels. This is very much like adding new dimensions to a Series or a DataFrame. For example, a Series is 1D, but by using a MultiIndex with 2 levels we gain of much the same functionality as a 2D DataFrame.\n",
    "\n",
    "The set of puzzles below explores how you might use multiple index levels to enhance data analysis.\n",
    "\n",
    "To warm up, we'll look make a Series with two index levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**44**. Given the lists `letters = ['A', 'B', 'C']` and `numbers = list(range(10))`, construct a MultiIndex object from the product of the two lists. Use it to index a Series of random numbers. Call this Series `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = ['A', 'B', 'C']\n",
    "numbers = list(range(10))\n",
    "\n",
    "mi = pd.MultiIndex.from_product([letters, numbers])\n",
    "s = pd.Series(np.random.rand(30), index=mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**45.** Check the index of `s` is lexicographically sorted (this is a necessary proprty for indexing to work correctly with a MultiIndex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.index.is_lexsorted()\n",
    "\n",
    "# or more verbosely...\n",
    "s.index.lexsort_depth == s.index.nlevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**46**. Select the labels `1`, `3` and `6` from the second level of the MultiIndexed Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.loc[:, [1, 3, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**47**. Slice the Series `s`; slice up to label 'B' for the first level and from label 5 onwards for the second level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.loc[pd.IndexSlice[:'B', 5:]]\n",
    "\n",
    "# or equivalently without IndexSlice...\n",
    "s.loc[slice(None, 'B'), slice(5, None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**48**. Sum the values in `s` for each label in the first level (you should have Series giving you a total for labels A, B and C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.sum(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**49**. Suppose that `sum()` (and other methods) did not accept a `level` keyword argument. How else could you perform the equivalent of `s.sum(level=1)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One way is to use .unstack()... \n",
    "# This method should convince you that s is essentially \n",
    "# just a regular DataFrame in disguise!\n",
    "s.unstack().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**50**. Exchange the levels of the MultiIndex so we have an index of the form (letters, numbers). Is this new Series properly lexsorted? If not, sort it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_s = s.swaplevel(0, 1)\n",
    "\n",
    "# check\n",
    "new_s.index.is_lexsorted()\n",
    "\n",
    "# sort\n",
    "new_s = new_s.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Minesweeper\n",
    "\n",
    "### Generate the numbers for safe squares in a Minesweeper grid\n",
    "\n",
    "Difficulty: *medium* to *hard*\n",
    "\n",
    "If you've ever used an older version of Windows, there's a good chance you've played with [Minesweeper](https://en.wikipedia.org/wiki/Minesweeper_(video_game). If you're not familiar with the game, imagine a grid of squares: some of these squares conceal a mine. If you click on a mine, you lose instantly. If you click on a safe square, you reveal a number telling you how many mines are found in the squares that are immediately adjacent. The aim of the game is to uncover all squares in the grid that do not contain a mine.\n",
    "\n",
    "In this section, we'll make a DataFrame that contains the necessary data for a game of Minesweeper: coordinates of the squares, whether the square contains a mine and the number of mines found on adjacent squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**51**. Let's suppose we're playing Minesweeper on a 5 by 4 grid, i.e.\n",
    "```\n",
    "X = 5\n",
    "Y = 4\n",
    "```\n",
    "To begin, generate a DataFrame `df` with two columns, `'x'` and `'y'` containing every coordinate for this grid. That is, the DataFrame should start:\n",
    "```\n",
    "   x  y\n",
    "0  0  0\n",
    "1  0  1\n",
    "2  0  2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pd.tools.util.cartesian_product([np.arange(X), np.arange(Y)])\n",
    "df = pd.DataFrame(np.asarray(p).T, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**52**. For this DataFrame `df`, create a new column of zeros (safe) and ones (mine). The probability of a mine occuring at each location should be 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One way is to draw samples from a binomial distribution.\n",
    "\n",
    "df['mine'] = np.random.binomial(1, 0.4, X*Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**53**. Now create a new column for this DataFrame called `'adjacent'`. This column should contain the number of mines found on adjacent squares in the grid. \n",
    "\n",
    "(E.g. for the first row, which is the entry for the coordinate `(0, 0)`, count how many mines are found on the coordinates `(0, 1)`, `(1, 0)` and `(1, 1)`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is one way to solve using merges.\n",
    "# It's not necessary the optimal way, just \n",
    "# the solution I thought of first...\n",
    "\n",
    "df['adjacent'] = \\\n",
    "    df.merge(df + [ 1,  1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 1, -1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [-1,  1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [-1, -1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 1,  0, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [-1,  0, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 0,  1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 0, -1, 0], on=['x', 'y'], how='left')\\\n",
    "       .iloc[:, 3:]\\\n",
    "        .sum(axis=1)\n",
    "        \n",
    "# An alternative solution is to pivot the DataFrame \n",
    "# to form the \"actual\" grid of mines and use convolution.\n",
    "# See https://github.com/jakevdp/matplotlib_pydata2013/blob/master/examples/minesweeper.py\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "mine_grid = df.pivot_table(columns='x', index='y', values='mine')\n",
    "counts = convolve2d(mine_grid.astype(complex), np.ones((3, 3)), mode='same').real.astype(int)\n",
    "df['adjacent'] = (counts - mine_grid).ravel('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**54**. For rows of the DataFrame that contain a mine, set the value in the `'adjacent'` column to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['mine'] == 1, 'adjacent'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**55**. Finally, convert the DataFrame to grid of the adjacent mine counts: columns are the `x` coordinate, rows are the `y` coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('mine', axis=1)\\\n",
    "  .set_index(['y', 'x']).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*More exercises to follow soon...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
